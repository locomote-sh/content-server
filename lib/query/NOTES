# Refactoring query.api to allow relocatable hosting.

Want to allow the query.api to be hosted in two contexts:

1. The current locomote-content-server context;
2. A new dev server context.

The second context will differ from the current context in the following ways:

* Use an in-memory IndexedDB implementation [https://github.com/dumbmatter/fakeIndexedDB]
* Full filedb support will not be available; this is because the dev server will be
  serving files direct from the file-system, rather than direct from the git repo.

The query module's external dependencies (both modules and services) are:

* pipeline.lineParser - this could be moved to an external module
* settings[publish.cache.location] - this is actually required by the IndexedDB implementation
  (as the location of its file cache) so could be refactored; but the settings module
  could also be made an external module.
* builder.on('content-repo-update') - this should be refactored to an app level event, so
  that there is no dependency on a specific sub-service
* filedb.listUpdatesSince and filedb.listAllFiles - both these calls are currently wrapped
  within a single listFileUpdates function, which in turn is called from an updateDB
  function - possible refactor needed to allow updates to be sourced from alternative sources.
 
The query module currently uses the following procedure to handle requests:

* check if requested origin is in sync by consulting a lookup table
* if not in sync then:
    * ensure a location for the cached idb
    * updated the idb by:
        * reading the latest commit in the idb
        * listing file updates since the reference commit
        * process each update and write to idb
    * mark the origin as in sync
* continue with request
* meanwhile, when a content repo is updated, remove any corresponding entry from the in sync lookup

The query module running in the dev server will have the following differences:

* only one, in-memory version of the idb
* updated files will be reported to it
* as no file db available, file records will need to be generated before updating the idb

The filedb module has a makeFileRecord function (in support) with dependencies:
* getFileset -> fileset.getFilesets

filedb.fileset could be made an external module, its dependencies are:
* fileglob
* utils (fingerprint)
* git (readFileAtCommit + pipeFileAtCommit)

Note that some way would be needed to abstract out the reading of files, to allow file contents to be
read both from a git repo, and from the file-system; this can probably be done by moving all file
access code to FilesetProcessor, and then adding some kind of switch to support a non-git mode; but
node that the data model does assume an underlying repo, and has repoPath + commit vars throughout.



DEPENDENCIES:

x pipeline:
    -> cmds:
        * exists
        * ensureDirForFile
    -> tinytemper

x filesets: (newly externalised version)
    -> fileglob:
        * makeCompliment
    -> utils:
        * fingerprint

x query:
    -> cmds:
        * ensureDir
    -> utils:
        * fingerprint   (move fingerprint to cmds)
    -> pipeline:
        * lineParser

dev-server:
    :: query (internal)
        * updateDB:
            -> filesets:
                * makeFileReord
        -> query
    :: http-api (internal)
        * [get file record]
            -> filesets
                * makeFileRecord


x tinytemper:

x fileglob:

